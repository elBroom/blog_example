{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification\n",
    "\n",
    "![title](MachineLearningDiagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification\n",
    "Имеется множество объектов, разделенных некоторым образом на классы.\n",
    "\n",
    "Для каких-то объектов известно к какому классу они относятся (выборка), для остальных -- нет.\n",
    "\n",
    "Требуется построить алгоритм, способный классифицировать произвольный объект из исходного множества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification\n",
    "\n",
    "* Каждый объект описывается набором признаков $x_1, x_2 ... x_m$, а также известно значение переменной, которую мы пытаемся предсказать $y$\n",
    "* $y$ - дискретная переменная, которая описывает класс объекта:\n",
    "$ y \\in Y : Y = {c_1, c_2, ..., c_k} $\n",
    "* Всё объекты можно представить в виде матрицы $X$ размера $ n \\times m $, где $n$ - количество объектов и $m$ - количество признаков\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Задача классификации заключается в нахождении зависимости дискретной переменной $y$ от вектора признаков $(x_1, x_2, ..., x_m)$: $$ f(x_1, x_2, ... x_m) = f(x) ~ y $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Classification examples\n",
    "* Диагностика заболеваний: два класса - болен / не болен\n",
    "* Письма в почтовом ящике: два класса - спам / не спам\n",
    "* Iris dataset: три класса описывающие различные виды растений\n",
    "* Классификация патогенных / непатогенных бактерий\n",
    "* Классификация изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import warnings\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "# import some data to play with\n",
    "iris = sb.load_dataset(\"iris\")\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sb.pairplot(iris, hue=\"species\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## K-nn\n",
    "K-nn = K nearest neighbors = K ближайших соседей\n",
    "\n",
    "Очень простой метод классификации:\n",
    "\n",
    "* Пускай про какие-то объекты известны их классы\n",
    "* Чтобы классифицировать объект неизвестного класса достаточно посмотреть на $k$ ближайших соседей этого объекта с известным классом\n",
    "* Выбрать тот класс, который наиболее представлен среди соседей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Profit!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## K-nn, n = 3\n",
    "<img src=\"KNN_class_img/classification-02.png\" width=\"500px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## K-nn, n = 3\n",
    "<img src=\"KNN_class_img/classification-03.png\" width=\"500px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## K-nn, n = 3\n",
    "<img src=\"KNN_class_img/classification-04.png\" width=\"500px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## K-nn, n = 3\n",
    "<img src=\"KNN_class_img/classification-05.png\" width=\"500px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## K-nn, n = 3\n",
    "<img src=\"KNN_class_img/classification-06.png\" width=\"500px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## K-nn, n = 3\n",
    "<img src=\"KNN_class_img/classification-07.png\" width=\"500px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## K-nn, n = 3\n",
    "<img src=\"KNN_class_img/classification-08.png\" width=\"500px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## K-nn, n = 3\n",
    "<img src=\"KNN_class_img/classification-09.png\" width=\"500px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## K-nn, n = 3\n",
    "<img src=\"KNN_class_img/classification-10.png\" width=\"500px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## K-nn, n = 3\n",
    "<img src=\"KNN_class_img/classification-11.png\" width=\"500px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## K-nn, n = 3\n",
    "<img src=\"KNN_class_img/classification-12.png\" width=\"500px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## K-nn, n = 3\n",
    "<img src=\"KNN_class_img/classification-13.png\" width=\"500px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## K-nn, n = 3\n",
    "<img src=\"KNN_class_img/classification-14.png\" width=\"500px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## K-nn, n = 3\n",
    "<img src=\"KNN_class_img/classification-15.png\" width=\"500px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## K-nn, n = 3\n",
    "<img src=\"KNN_class_img/classification-16.png\" width=\"500px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loading iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "data = iris.data\n",
    "\n",
    "train, test = train_test_split(range(len(data)), test_size=0.2)\n",
    "\n",
    "train_data = data[train, :]\n",
    "test_data = data[test, :]\n",
    "\n",
    "train_y = iris.target[train]\n",
    "test_y = iris.target[test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Teaching the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "neighbors = np.arange(1,15)\n",
    "\n",
    "errors_df = pd.DataFrame(\n",
    "    data = np.zeros([len(neighbors), 2]),\n",
    "    index = neighbors,\n",
    "    columns = [\"train_accuracy\", \"test_accuracy\"]\n",
    ")\n",
    "\n",
    "for i,k in enumerate(neighbors):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(train_data, train_y)\n",
    "    \n",
    "    errors_df.iloc[i, 0] = knn.score(train_data, train_y)\n",
    "    errors_df.iloc[i, 1] = knn.score(test_data, test_y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualizing an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "errors_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quick conclusions\n",
    "\n",
    "В нашем случае точность пости случайно зависит от количества соседей: даже в худшем случае, мы разделяем множества очень хорошо.\n",
    "\n",
    "Точность отдельного классификатора удобно рассматривать, с помощью confusion matrix для тренировочного датасета.\n",
    "\n",
    "Confusion matrix показывает, как часто мы угадываем\\ошибаемся в классификации объектов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(train_data, train_y)\n",
    "pred_y = knn.predict(test_data)\n",
    "confusion_matrix(test_y, pred_y, labels=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## K-nn\n",
    "Плюсы:\n",
    "\n",
    "* Просто, быстро и понятно\n",
    "* Несложно сделать из этого регрессию (брать взвешенное среднее соседей)\n",
    "\n",
    "Минусы:\n",
    "\n",
    "* Нужно чтобы данные можно было представить как точки в многомерном Евклидовом пространстве\n",
    "* Нужно чтобы расстояние между этими точками действительно отражало \"похожесть\" и \"непохожесть\" объектов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Binary classification\n",
    "Важнейшая подзадача задачи классификации.\n",
    "\n",
    "Наше множество классов $Y$ представлено лишь двумя классами: $$ Y = c_1, c_2 $$\n",
    "\n",
    "это может быть положительная/отрицательная диагностика заболевания, определение спам/не спам и другие типы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.io.arff import loadarff\n",
    "\n",
    "data, names = loadarff(\"diabetes.arff.txt\")\n",
    "data = pd.DataFrame(data=data)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Binary classification metrics\n",
    "\n",
    "$$ Precision = \\frac{TP}{TP + FP} $$\n",
    "\n",
    "$$ Recall (TPR) = \\frac{TP}{TP + FN} $$\n",
    "\n",
    "$$ Accuracy =  \\frac{TP + TN}{ TP + FP + TN + FN} $$\n",
    "\n",
    "$$ FPR = \\frac{FP}{FP + TN} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Logistic regression\n",
    "\n",
    "* Метод \"регрессии\", когда зависимая переменная $y$ описывается дискретным множеством классов.\n",
    "* Логистическая регрессия очень часто применяется в контексте бинарной классификации.\n",
    "* Почему регрессия?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Logistic regression\n",
    "\n",
    "<img src=\"Exam_pass_logistic_curve.jpeg\" width=\"800px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Splitting data to train/test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "train, test = train_test_split(range(len(data)), test_size=0.2)\n",
    "\n",
    "train_data = data.iloc[train, 0:8].as_matrix()\n",
    "test_data = data.iloc[test, 0:8].as_matrix()\n",
    "\n",
    "train_y = data.iloc[train, 8].values\n",
    "test_y = data.iloc[test, 8].values\n",
    "\n",
    "mapping = {\n",
    "    b'tested_positive': 1,\n",
    "    b'tested_negative': 0\n",
    "}\n",
    "\n",
    "train_y = list(map(lambda x: mapping[x], train_y))\n",
    "test_y = list(map(lambda x: mapping[x], test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Train logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "logisticRegressor = LogisticRegression()\n",
    "logisticRegressor.fit(train_data, train_y)\n",
    "\n",
    "pred_y = logisticRegressor.predict(test_data)\n",
    "confusion_matrix(test_y, pred_y, labels=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using probabilites\n",
    "\n",
    "<img src=\"error_types.PNG\" width=\"400px\"/>\n",
    "\n",
    "* В задаче классификации ошибки бывают разного вида, и в диагностике допустить ошибку может быть ползволительно, в то время, как допустить ошибку другого вида может быть очень плохо.\n",
    "\n",
    "* Мы можем использовать вероятности логистической регрессии, чтобы настроить наш классификатор в ту или иную сторону\n",
    "\n",
    "* В нашем случае у нас слишком много ошибок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Choosing threshold\n",
    "\n",
    "* Часто в диагностике False Negative не так страшно как False Positive, особенно в методах диагностики и предиагностики\n",
    "* В методах предиагностики мы должны отправить человека с потенциальным заболеванием на дообследование\n",
    "* Мы можем построить ROC-кривую: зависимость True Positive Rate от False Positive Rate в зависимости от threshold\n",
    "* Какой такой threshold?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Calulating probabilites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "prob_y = logisticRegressor.predict_proba(test_data)\n",
    "prob_y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Calculating TPR, FPR and area under curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(test_y, prob_y[:, 1])\n",
    "auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Plotting ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color=\"darkorange\", label=\"ROC curve (area = %0.2f)\" % auc)\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", linestyle=\"--\")\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
